{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_1488834.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8XtcgbGj5xN",
        "colab_type": "text"
      },
      "source": [
        "#Finding optimal hyper-parameters for CIFAR10 Images\n",
        "\n",
        "#Student Name: zijun wu\n",
        "\n",
        "#Student id: 1488834"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4BNOnZe46CQ",
        "colab_type": "code",
        "outputId": "5869c5b3-5d02-4f46-83ce-88e0cea73816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "epochs = 5\n",
        "batch_size_train = 128\n",
        "batch_size_test = 1000\n",
        "learning_rate = 1e-3\n",
        "momentum = 0.5\n",
        "log_interval = 100\n",
        "optimizer_name=\"Adam\"\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Checking GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWd5IGhbkCnz",
        "colab_type": "text"
      },
      "source": [
        "## Divide CIFAR10 into training, validation and test sets\n",
        "## Use DataLoader iterator for loading data in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2uiYpfC4_aW",
        "colab_type": "code",
        "outputId": "6e939d96-967c-4798-915b-8d2b8b18ad22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "CIFAR10_training = torchvision.datasets.CIFAR10('/CIFAR10_dataset/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "CIFAR10_test_set = torchvision.datasets.CIFAR10('/CIFAR10_dataset/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "# create a training and a validation set\n",
        "CIFAR10_training_set, CIFAR10_validation_set = random_split(CIFAR10_training, [45000, 5000])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(CIFAR10_training_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(CIFAR10_validation_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(CIFAR10_test_set,batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1MU6Yh56HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multiple Linear regression\n",
        "class MultipleLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultipleLinearRegression, self).__init__()\n",
        "        self.fc = nn.Linear(32*32*3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTl6EgA_lwyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Following code appears at:  https://lirnli.wordpress.com/2017/09/03/one-hot-encoding-in-pytorch/\n",
        "class One_Hot(nn.Module):\n",
        "    def __init__(self, depth):\n",
        "        super(One_Hot,self).__init__()\n",
        "        self.depth = depth\n",
        "        self.ones = torch.sparse.torch.eye(depth).to(device)\n",
        "    def forward(self, X_in):\n",
        "        X_in = X_in.long()\n",
        "        return self.ones.index_select(0,X_in.data)\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"({})\".format(self.depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy8SKSrG6KxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(multi_linear_model, learning_rate=0.0001, momentum=0.5, epochs=2, optimizer_name=\"Adam\"):\n",
        "  multi_linear_model.train()\n",
        "  if optimizer_name == \"Adam\":\n",
        "      optimizer = optim.Adam(multi_linear_model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "      \n",
        "  elif optimizer_name == \"SGD\":\n",
        "      optimizer = optim.SGD(multi_linear_model.parameters(), lr=learning_rate, momentum=momentum,weight_decay=0.01)\n",
        "    \n",
        "  for epoch in range(1, epochs + 1):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = multi_linear_model(data)\n",
        "      loss = F.mse_loss(output, one_hot(target)) # notice the use of view_as\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      error = loss.item();\n",
        "    print('EPOCH {} completed. learning_rate= {:.6f}, Training Loss: {:.4f}'.format( epoch,learning_rate,error))\n",
        "  return error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr4Bd0BI6P7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(multi_linear_model):\n",
        "  multi_linear_model.eval()\n",
        "  validation_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # notice the use of no_grad\n",
        "    for data, target in validation_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = multi_linear_model(data)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "      validation_loss += F.mse_loss(output, one_hot(target), size_average=False).item()\n",
        "  validation_loss /= len(validation_loader.dataset)\n",
        "  print('Validation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(validation_loss, correct, len(validation_loader.dataset), 100. * correct / len(validation_loader.dataset)))\n",
        "  return 100. * correct / len(validation_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGcIxeFW0rR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(multi_linear_model):\n",
        "  multi_linear_model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = multi_linear_model(data)\n",
        "      test_loss += F.mse_loss(output, one_hot(target), size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "  return 100. * correct / len(test_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjjozQl6ARg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_hyper_parameter():\n",
        "  # -- Your code goes here --\n",
        "\n",
        "  import numpy as np\n",
        "  np.random.seed(1)\n",
        "  ## Perform your hyper-parameter search for Adam\n",
        "  adam_grid_value = np.random.uniform(low=0.00001, high=0.0001, size=(10,))\n",
        "  # adam_grid_value = [0.000109, 0.000108, 0.000107, 0.000106, 0.000105]\n",
        "  adam_accuracy = 0\n",
        "  adam_test_accuracy = 0\n",
        "  adam_lr_value = 0\n",
        "  for value in adam_grid_value:\n",
        "    multi_linear_model = MultipleLinearRegression().to(device)\n",
        "    train(multi_linear_model, epochs=5, learning_rate=value)\n",
        "    accuracy = validation(multi_linear_model)\n",
        "    if accuracy > adam_accuracy:\n",
        "      adam_accuracy = accuracy\n",
        "      adam_lr_value = value\n",
        "      adam_test_accuracy = test(multi_linear_model)\n",
        "\n",
        "  print('Best performance: Validation Accuracy={:.0f}%, Test Accuracy={:.0f}%, with Adam optimizer learning_rate={}'.format(adam_accuracy, adam_test_accuracy, adam_lr_value))\n",
        "\n",
        "  \n",
        "  ## Perform your hyper-parameter search for SGD   \n",
        "  SGD_grid_value = {\"lr\": np.random.uniform(low=0.0001, high=0.0009, size=(10,)),\n",
        "                    \"momentum\": np.random.uniform(low=0.95, high=0.99, size=(5,))}\n",
        "  SGD_accuracy = 0\n",
        "  SGD_test_accuracy = 0\n",
        "  SGD_lr_value = 0\n",
        "  SGD_monentum_value = 0\n",
        "  for lr in SGD_grid_value[\"lr\"]:\n",
        "    for momentum in SGD_grid_value[\"momentum\"]:\n",
        "      multi_linear_model = MultipleLinearRegression().to(device)\n",
        "      train(multi_linear_model, learning_rate=lr, momentum=momentum, epochs=5, optimizer_name=\"SGD\")\n",
        "      accuracy = validation(multi_linear_model)\n",
        "      if accuracy > SGD_accuracy:\n",
        "        SGD_accuracy = accuracy\n",
        "        SGD_lr_value = lr\n",
        "        SGD_monentum_value = momentum\n",
        "        SGD_test_accuracy = test(multi_linear_model)\n",
        "\n",
        "  print('Best performance: Validation Accuracy={:.0f}%,  Test Accuracy={:.0f}%, with SGD optimizer learning_rate={} and momentum={}'.format(SGD_accuracy, SGD_test_accuracy, SGD_lr_value, SGD_monentum_value))\n",
        "\n",
        "    \n",
        "  ##Final output will be like:\n",
        "  \n",
        "  #Best performance: Validation Accuracy=38% , with Adam optimizer learning_rate=0.??????\n",
        "  \n",
        "  #or\n",
        "  \n",
        "  #Best performance: Validation Accuracy=37% , with SGD optimizer learning_rate=0.?????? and momentum=0.???\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRG7c7Sy6XOs",
        "colab_type": "code",
        "outputId": "3313cbd5-2a48-4938-f30c-3a54a6fb7a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##Final Block\n",
        "##Keep the output block of this section while submitting your solution \n",
        "##The last line of the output must contain the accuracy and best configuration information\n",
        "multi_linear_model = MultipleLinearRegression().to(device)\n",
        "one_hot = One_Hot(10).to(device)\n",
        "validation(multi_linear_model)\n",
        "tune_hyper_parameter()\n",
        "        \n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set: Avg. loss: 1.8523, Accuracy: 479/5000 (9%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000048, Training Loss: 0.0876\n",
            "EPOCH 2 completed. learning_rate= 0.000048, Training Loss: 0.0862\n",
            "EPOCH 3 completed. learning_rate= 0.000048, Training Loss: 0.0846\n",
            "EPOCH 4 completed. learning_rate= 0.000048, Training Loss: 0.0863\n",
            "EPOCH 5 completed. learning_rate= 0.000048, Training Loss: 0.0810\n",
            "Validation set: Avg. loss: 0.8150, Accuracy: 1920/5000 (38%)\n",
            "\n",
            "Test set: Avg. loss: 0.8167, Accuracy: 3812/10000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000075, Training Loss: 0.0872\n",
            "EPOCH 2 completed. learning_rate= 0.000075, Training Loss: 0.0917\n",
            "EPOCH 3 completed. learning_rate= 0.000075, Training Loss: 0.0800\n",
            "EPOCH 4 completed. learning_rate= 0.000075, Training Loss: 0.0815\n",
            "EPOCH 5 completed. learning_rate= 0.000075, Training Loss: 0.0793\n",
            "Validation set: Avg. loss: 0.8064, Accuracy: 1875/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000010, Training Loss: 0.1067\n",
            "EPOCH 2 completed. learning_rate= 0.000010, Training Loss: 0.1042\n",
            "EPOCH 3 completed. learning_rate= 0.000010, Training Loss: 0.0952\n",
            "EPOCH 4 completed. learning_rate= 0.000010, Training Loss: 0.0915\n",
            "EPOCH 5 completed. learning_rate= 0.000010, Training Loss: 0.0903\n",
            "Validation set: Avg. loss: 0.9010, Accuracy: 1559/5000 (31%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000037, Training Loss: 0.0901\n",
            "EPOCH 2 completed. learning_rate= 0.000037, Training Loss: 0.0932\n",
            "EPOCH 3 completed. learning_rate= 0.000037, Training Loss: 0.0900\n",
            "EPOCH 4 completed. learning_rate= 0.000037, Training Loss: 0.0832\n",
            "EPOCH 5 completed. learning_rate= 0.000037, Training Loss: 0.0815\n",
            "Validation set: Avg. loss: 0.8270, Accuracy: 1859/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000023, Training Loss: 0.0985\n",
            "EPOCH 2 completed. learning_rate= 0.000023, Training Loss: 0.0878\n",
            "EPOCH 3 completed. learning_rate= 0.000023, Training Loss: 0.0863\n",
            "EPOCH 4 completed. learning_rate= 0.000023, Training Loss: 0.0870\n",
            "EPOCH 5 completed. learning_rate= 0.000023, Training Loss: 0.0857\n",
            "Validation set: Avg. loss: 0.8468, Accuracy: 1770/5000 (35%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000018, Training Loss: 0.0949\n",
            "EPOCH 2 completed. learning_rate= 0.000018, Training Loss: 0.0941\n",
            "EPOCH 3 completed. learning_rate= 0.000018, Training Loss: 0.0932\n",
            "EPOCH 4 completed. learning_rate= 0.000018, Training Loss: 0.0867\n",
            "EPOCH 5 completed. learning_rate= 0.000018, Training Loss: 0.0872\n",
            "Validation set: Avg. loss: 0.8636, Accuracy: 1690/5000 (33%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000027, Training Loss: 0.0982\n",
            "EPOCH 2 completed. learning_rate= 0.000027, Training Loss: 0.0923\n",
            "EPOCH 3 completed. learning_rate= 0.000027, Training Loss: 0.0883\n",
            "EPOCH 4 completed. learning_rate= 0.000027, Training Loss: 0.0845\n",
            "EPOCH 5 completed. learning_rate= 0.000027, Training Loss: 0.0857\n",
            "Validation set: Avg. loss: 0.8422, Accuracy: 1782/5000 (35%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000041, Training Loss: 0.0875\n",
            "EPOCH 2 completed. learning_rate= 0.000041, Training Loss: 0.0912\n",
            "EPOCH 3 completed. learning_rate= 0.000041, Training Loss: 0.0829\n",
            "EPOCH 4 completed. learning_rate= 0.000041, Training Loss: 0.0856\n",
            "EPOCH 5 completed. learning_rate= 0.000041, Training Loss: 0.0809\n",
            "Validation set: Avg. loss: 0.8259, Accuracy: 1835/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000046, Training Loss: 0.0965\n",
            "EPOCH 2 completed. learning_rate= 0.000046, Training Loss: 0.0856\n",
            "EPOCH 3 completed. learning_rate= 0.000046, Training Loss: 0.0881\n",
            "EPOCH 4 completed. learning_rate= 0.000046, Training Loss: 0.0825\n",
            "EPOCH 5 completed. learning_rate= 0.000046, Training Loss: 0.0808\n",
            "Validation set: Avg. loss: 0.8188, Accuracy: 1910/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000058, Training Loss: 0.0860\n",
            "EPOCH 2 completed. learning_rate= 0.000058, Training Loss: 0.0868\n",
            "EPOCH 3 completed. learning_rate= 0.000058, Training Loss: 0.0852\n",
            "EPOCH 4 completed. learning_rate= 0.000058, Training Loss: 0.0780\n",
            "EPOCH 5 completed. learning_rate= 0.000058, Training Loss: 0.0808\n",
            "Validation set: Avg. loss: 0.8132, Accuracy: 1859/5000 (37%)\n",
            "\n",
            "Best performance: Validation Accuracy=38%, Test Accuracy=38%, with Adam optimizer learning_rate=4.7531980423231664e-05\n",
            "EPOCH 1 completed. learning_rate= 0.000435, Training Loss: 0.0889\n",
            "EPOCH 2 completed. learning_rate= 0.000435, Training Loss: 0.0857\n",
            "EPOCH 3 completed. learning_rate= 0.000435, Training Loss: 0.0786\n",
            "EPOCH 4 completed. learning_rate= 0.000435, Training Loss: 0.0839\n",
            "EPOCH 5 completed. learning_rate= 0.000435, Training Loss: 0.0832\n",
            "Validation set: Avg. loss: 0.8066, Accuracy: 1834/5000 (36%)\n",
            "\n",
            "Test set: Avg. loss: 0.8036, Accuracy: 3765/10000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000435, Training Loss: 0.0848\n",
            "EPOCH 2 completed. learning_rate= 0.000435, Training Loss: 0.0850\n",
            "EPOCH 3 completed. learning_rate= 0.000435, Training Loss: 0.0821\n",
            "EPOCH 4 completed. learning_rate= 0.000435, Training Loss: 0.0811\n",
            "EPOCH 5 completed. learning_rate= 0.000435, Training Loss: 0.0838\n",
            "Validation set: Avg. loss: 0.8057, Accuracy: 1865/5000 (37%)\n",
            "\n",
            "Test set: Avg. loss: 0.8045, Accuracy: 3820/10000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000435, Training Loss: 0.0923\n",
            "EPOCH 2 completed. learning_rate= 0.000435, Training Loss: 0.0830\n",
            "EPOCH 3 completed. learning_rate= 0.000435, Training Loss: 0.0802\n",
            "EPOCH 4 completed. learning_rate= 0.000435, Training Loss: 0.0823\n",
            "EPOCH 5 completed. learning_rate= 0.000435, Training Loss: 0.0774\n",
            "Validation set: Avg. loss: 0.8111, Accuracy: 1841/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000435, Training Loss: 0.0877\n",
            "EPOCH 2 completed. learning_rate= 0.000435, Training Loss: 0.0826\n",
            "EPOCH 3 completed. learning_rate= 0.000435, Training Loss: 0.0792\n",
            "EPOCH 4 completed. learning_rate= 0.000435, Training Loss: 0.0764\n",
            "EPOCH 5 completed. learning_rate= 0.000435, Training Loss: 0.0813\n",
            "Validation set: Avg. loss: 0.8020, Accuracy: 1931/5000 (38%)\n",
            "\n",
            "Test set: Avg. loss: 0.8029, Accuracy: 3840/10000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000435, Training Loss: 0.0864\n",
            "EPOCH 2 completed. learning_rate= 0.000435, Training Loss: 0.0856\n",
            "EPOCH 3 completed. learning_rate= 0.000435, Training Loss: 0.0826\n",
            "EPOCH 4 completed. learning_rate= 0.000435, Training Loss: 0.0756\n",
            "EPOCH 5 completed. learning_rate= 0.000435, Training Loss: 0.0790\n",
            "Validation set: Avg. loss: 0.8004, Accuracy: 1918/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000648, Training Loss: 0.0864\n",
            "EPOCH 2 completed. learning_rate= 0.000648, Training Loss: 0.0833\n",
            "EPOCH 3 completed. learning_rate= 0.000648, Training Loss: 0.0799\n",
            "EPOCH 4 completed. learning_rate= 0.000648, Training Loss: 0.0814\n",
            "EPOCH 5 completed. learning_rate= 0.000648, Training Loss: 0.0805\n",
            "Validation set: Avg. loss: 0.8004, Accuracy: 1923/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000648, Training Loss: 0.0877\n",
            "EPOCH 2 completed. learning_rate= 0.000648, Training Loss: 0.0790\n",
            "EPOCH 3 completed. learning_rate= 0.000648, Training Loss: 0.0799\n",
            "EPOCH 4 completed. learning_rate= 0.000648, Training Loss: 0.0776\n",
            "EPOCH 5 completed. learning_rate= 0.000648, Training Loss: 0.0809\n",
            "Validation set: Avg. loss: 0.8141, Accuracy: 1818/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000648, Training Loss: 0.0869\n",
            "EPOCH 2 completed. learning_rate= 0.000648, Training Loss: 0.0893\n",
            "EPOCH 3 completed. learning_rate= 0.000648, Training Loss: 0.0830\n",
            "EPOCH 4 completed. learning_rate= 0.000648, Training Loss: 0.0820\n",
            "EPOCH 5 completed. learning_rate= 0.000648, Training Loss: 0.0826\n",
            "Validation set: Avg. loss: 0.8036, Accuracy: 1903/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000648, Training Loss: 0.0807\n",
            "EPOCH 2 completed. learning_rate= 0.000648, Training Loss: 0.0900\n",
            "EPOCH 3 completed. learning_rate= 0.000648, Training Loss: 0.0815\n",
            "EPOCH 4 completed. learning_rate= 0.000648, Training Loss: 0.0783\n",
            "EPOCH 5 completed. learning_rate= 0.000648, Training Loss: 0.0805\n",
            "Validation set: Avg. loss: 0.8051, Accuracy: 1888/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000648, Training Loss: 0.0818\n",
            "EPOCH 2 completed. learning_rate= 0.000648, Training Loss: 0.0765\n",
            "EPOCH 3 completed. learning_rate= 0.000648, Training Loss: 0.0856\n",
            "EPOCH 4 completed. learning_rate= 0.000648, Training Loss: 0.0790\n",
            "EPOCH 5 completed. learning_rate= 0.000648, Training Loss: 0.0783\n",
            "Validation set: Avg. loss: 0.8026, Accuracy: 1896/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000264, Training Loss: 0.0840\n",
            "EPOCH 2 completed. learning_rate= 0.000264, Training Loss: 0.0853\n",
            "EPOCH 3 completed. learning_rate= 0.000264, Training Loss: 0.0817\n",
            "EPOCH 4 completed. learning_rate= 0.000264, Training Loss: 0.0874\n",
            "EPOCH 5 completed. learning_rate= 0.000264, Training Loss: 0.0776\n",
            "Validation set: Avg. loss: 0.8068, Accuracy: 1830/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000264, Training Loss: 0.0885\n",
            "EPOCH 2 completed. learning_rate= 0.000264, Training Loss: 0.0806\n",
            "EPOCH 3 completed. learning_rate= 0.000264, Training Loss: 0.0745\n",
            "EPOCH 4 completed. learning_rate= 0.000264, Training Loss: 0.0820\n",
            "EPOCH 5 completed. learning_rate= 0.000264, Training Loss: 0.0805\n",
            "Validation set: Avg. loss: 0.8040, Accuracy: 1887/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000264, Training Loss: 0.0970\n",
            "EPOCH 2 completed. learning_rate= 0.000264, Training Loss: 0.0903\n",
            "EPOCH 3 completed. learning_rate= 0.000264, Training Loss: 0.0894\n",
            "EPOCH 4 completed. learning_rate= 0.000264, Training Loss: 0.0820\n",
            "EPOCH 5 completed. learning_rate= 0.000264, Training Loss: 0.0782\n",
            "Validation set: Avg. loss: 0.8269, Accuracy: 1712/5000 (34%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000264, Training Loss: 0.0922\n",
            "EPOCH 2 completed. learning_rate= 0.000264, Training Loss: 0.0833\n",
            "EPOCH 3 completed. learning_rate= 0.000264, Training Loss: 0.0774\n",
            "EPOCH 4 completed. learning_rate= 0.000264, Training Loss: 0.0807\n",
            "EPOCH 5 completed. learning_rate= 0.000264, Training Loss: 0.0802\n",
            "Validation set: Avg. loss: 0.8102, Accuracy: 1867/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000264, Training Loss: 0.0848\n",
            "EPOCH 2 completed. learning_rate= 0.000264, Training Loss: 0.0840\n",
            "EPOCH 3 completed. learning_rate= 0.000264, Training Loss: 0.0834\n",
            "EPOCH 4 completed. learning_rate= 0.000264, Training Loss: 0.0793\n",
            "EPOCH 5 completed. learning_rate= 0.000264, Training Loss: 0.0793\n",
            "Validation set: Avg. loss: 0.8063, Accuracy: 1861/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000802, Training Loss: 0.0865\n",
            "EPOCH 2 completed. learning_rate= 0.000802, Training Loss: 0.0821\n",
            "EPOCH 3 completed. learning_rate= 0.000802, Training Loss: 0.0830\n",
            "EPOCH 4 completed. learning_rate= 0.000802, Training Loss: 0.0812\n",
            "EPOCH 5 completed. learning_rate= 0.000802, Training Loss: 0.0759\n",
            "Validation set: Avg. loss: 0.8009, Accuracy: 1887/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000802, Training Loss: 0.0838\n",
            "EPOCH 2 completed. learning_rate= 0.000802, Training Loss: 0.0782\n",
            "EPOCH 3 completed. learning_rate= 0.000802, Training Loss: 0.0816\n",
            "EPOCH 4 completed. learning_rate= 0.000802, Training Loss: 0.0751\n",
            "EPOCH 5 completed. learning_rate= 0.000802, Training Loss: 0.0790\n",
            "Validation set: Avg. loss: 0.8135, Accuracy: 1825/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000802, Training Loss: 0.0882\n",
            "EPOCH 2 completed. learning_rate= 0.000802, Training Loss: 0.0831\n",
            "EPOCH 3 completed. learning_rate= 0.000802, Training Loss: 0.0835\n",
            "EPOCH 4 completed. learning_rate= 0.000802, Training Loss: 0.0823\n",
            "EPOCH 5 completed. learning_rate= 0.000802, Training Loss: 0.0795\n",
            "Validation set: Avg. loss: 0.8032, Accuracy: 1911/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000802, Training Loss: 0.0846\n",
            "EPOCH 2 completed. learning_rate= 0.000802, Training Loss: 0.0837\n",
            "EPOCH 3 completed. learning_rate= 0.000802, Training Loss: 0.0769\n",
            "EPOCH 4 completed. learning_rate= 0.000802, Training Loss: 0.0793\n",
            "EPOCH 5 completed. learning_rate= 0.000802, Training Loss: 0.0765\n",
            "Validation set: Avg. loss: 0.8005, Accuracy: 1964/5000 (39%)\n",
            "\n",
            "Test set: Avg. loss: 0.8004, Accuracy: 3904/10000 (39%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000802, Training Loss: 0.0814\n",
            "EPOCH 2 completed. learning_rate= 0.000802, Training Loss: 0.0819\n",
            "EPOCH 3 completed. learning_rate= 0.000802, Training Loss: 0.0852\n",
            "EPOCH 4 completed. learning_rate= 0.000802, Training Loss: 0.0811\n",
            "EPOCH 5 completed. learning_rate= 0.000802, Training Loss: 0.0741\n",
            "Validation set: Avg. loss: 0.8018, Accuracy: 1887/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000122, Training Loss: 0.0903\n",
            "EPOCH 2 completed. learning_rate= 0.000122, Training Loss: 0.0845\n",
            "EPOCH 3 completed. learning_rate= 0.000122, Training Loss: 0.0855\n",
            "EPOCH 4 completed. learning_rate= 0.000122, Training Loss: 0.0835\n",
            "EPOCH 5 completed. learning_rate= 0.000122, Training Loss: 0.0814\n",
            "Validation set: Avg. loss: 0.8299, Accuracy: 1727/5000 (34%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000122, Training Loss: 0.0935\n",
            "EPOCH 2 completed. learning_rate= 0.000122, Training Loss: 0.0896\n",
            "EPOCH 3 completed. learning_rate= 0.000122, Training Loss: 0.0867\n",
            "EPOCH 4 completed. learning_rate= 0.000122, Training Loss: 0.0836\n",
            "EPOCH 5 completed. learning_rate= 0.000122, Training Loss: 0.0785\n",
            "Validation set: Avg. loss: 0.8143, Accuracy: 1837/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000122, Training Loss: 0.0998\n",
            "EPOCH 2 completed. learning_rate= 0.000122, Training Loss: 0.0948\n",
            "EPOCH 3 completed. learning_rate= 0.000122, Training Loss: 0.0902\n",
            "EPOCH 4 completed. learning_rate= 0.000122, Training Loss: 0.0892\n",
            "EPOCH 5 completed. learning_rate= 0.000122, Training Loss: 0.0847\n",
            "Validation set: Avg. loss: 0.8584, Accuracy: 1638/5000 (32%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000122, Training Loss: 0.0940\n",
            "EPOCH 2 completed. learning_rate= 0.000122, Training Loss: 0.0895\n",
            "EPOCH 3 completed. learning_rate= 0.000122, Training Loss: 0.0870\n",
            "EPOCH 4 completed. learning_rate= 0.000122, Training Loss: 0.0848\n",
            "EPOCH 5 completed. learning_rate= 0.000122, Training Loss: 0.0881\n",
            "Validation set: Avg. loss: 0.8341, Accuracy: 1737/5000 (34%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000122, Training Loss: 0.0955\n",
            "EPOCH 2 completed. learning_rate= 0.000122, Training Loss: 0.0898\n",
            "EPOCH 3 completed. learning_rate= 0.000122, Training Loss: 0.0845\n",
            "EPOCH 4 completed. learning_rate= 0.000122, Training Loss: 0.0858\n",
            "EPOCH 5 completed. learning_rate= 0.000122, Training Loss: 0.0820\n",
            "Validation set: Avg. loss: 0.8193, Accuracy: 1832/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000636, Training Loss: 0.0937\n",
            "EPOCH 2 completed. learning_rate= 0.000636, Training Loss: 0.0858\n",
            "EPOCH 3 completed. learning_rate= 0.000636, Training Loss: 0.0800\n",
            "EPOCH 4 completed. learning_rate= 0.000636, Training Loss: 0.0779\n",
            "EPOCH 5 completed. learning_rate= 0.000636, Training Loss: 0.0811\n",
            "Validation set: Avg. loss: 0.8046, Accuracy: 1879/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000636, Training Loss: 0.0810\n",
            "EPOCH 2 completed. learning_rate= 0.000636, Training Loss: 0.0785\n",
            "EPOCH 3 completed. learning_rate= 0.000636, Training Loss: 0.0810\n",
            "EPOCH 4 completed. learning_rate= 0.000636, Training Loss: 0.0786\n",
            "EPOCH 5 completed. learning_rate= 0.000636, Training Loss: 0.0829\n",
            "Validation set: Avg. loss: 0.8131, Accuracy: 1837/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000636, Training Loss: 0.0844\n",
            "EPOCH 2 completed. learning_rate= 0.000636, Training Loss: 0.0856\n",
            "EPOCH 3 completed. learning_rate= 0.000636, Training Loss: 0.0815\n",
            "EPOCH 4 completed. learning_rate= 0.000636, Training Loss: 0.0775\n",
            "EPOCH 5 completed. learning_rate= 0.000636, Training Loss: 0.0787\n",
            "Validation set: Avg. loss: 0.8050, Accuracy: 1931/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000636, Training Loss: 0.0817\n",
            "EPOCH 2 completed. learning_rate= 0.000636, Training Loss: 0.0804\n",
            "EPOCH 3 completed. learning_rate= 0.000636, Training Loss: 0.0809\n",
            "EPOCH 4 completed. learning_rate= 0.000636, Training Loss: 0.0787\n",
            "EPOCH 5 completed. learning_rate= 0.000636, Training Loss: 0.0769\n",
            "Validation set: Avg. loss: 0.8008, Accuracy: 1920/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000636, Training Loss: 0.0852\n",
            "EPOCH 2 completed. learning_rate= 0.000636, Training Loss: 0.0822\n",
            "EPOCH 3 completed. learning_rate= 0.000636, Training Loss: 0.0819\n",
            "EPOCH 4 completed. learning_rate= 0.000636, Training Loss: 0.0805\n",
            "EPOCH 5 completed. learning_rate= 0.000636, Training Loss: 0.0794\n",
            "Validation set: Avg. loss: 0.7997, Accuracy: 1927/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000434, Training Loss: 0.0827\n",
            "EPOCH 2 completed. learning_rate= 0.000434, Training Loss: 0.0807\n",
            "EPOCH 3 completed. learning_rate= 0.000434, Training Loss: 0.0810\n",
            "EPOCH 4 completed. learning_rate= 0.000434, Training Loss: 0.0798\n",
            "EPOCH 5 completed. learning_rate= 0.000434, Training Loss: 0.0849\n",
            "Validation set: Avg. loss: 0.8037, Accuracy: 1860/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000434, Training Loss: 0.0862\n",
            "EPOCH 2 completed. learning_rate= 0.000434, Training Loss: 0.0828\n",
            "EPOCH 3 completed. learning_rate= 0.000434, Training Loss: 0.0789\n",
            "EPOCH 4 completed. learning_rate= 0.000434, Training Loss: 0.0773\n",
            "EPOCH 5 completed. learning_rate= 0.000434, Training Loss: 0.0806\n",
            "Validation set: Avg. loss: 0.8032, Accuracy: 1902/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000434, Training Loss: 0.0936\n",
            "EPOCH 2 completed. learning_rate= 0.000434, Training Loss: 0.0862\n",
            "EPOCH 3 completed. learning_rate= 0.000434, Training Loss: 0.0819\n",
            "EPOCH 4 completed. learning_rate= 0.000434, Training Loss: 0.0834\n",
            "EPOCH 5 completed. learning_rate= 0.000434, Training Loss: 0.0855\n",
            "Validation set: Avg. loss: 0.8109, Accuracy: 1812/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000434, Training Loss: 0.0870\n",
            "EPOCH 2 completed. learning_rate= 0.000434, Training Loss: 0.0815\n",
            "EPOCH 3 completed. learning_rate= 0.000434, Training Loss: 0.0827\n",
            "EPOCH 4 completed. learning_rate= 0.000434, Training Loss: 0.0822\n",
            "EPOCH 5 completed. learning_rate= 0.000434, Training Loss: 0.0790\n",
            "Validation set: Avg. loss: 0.8022, Accuracy: 1922/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000434, Training Loss: 0.0847\n",
            "EPOCH 2 completed. learning_rate= 0.000434, Training Loss: 0.0807\n",
            "EPOCH 3 completed. learning_rate= 0.000434, Training Loss: 0.0818\n",
            "EPOCH 4 completed. learning_rate= 0.000434, Training Loss: 0.0786\n",
            "EPOCH 5 completed. learning_rate= 0.000434, Training Loss: 0.0783\n",
            "Validation set: Avg. loss: 0.8023, Accuracy: 1927/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000547, Training Loss: 0.0916\n",
            "EPOCH 2 completed. learning_rate= 0.000547, Training Loss: 0.0876\n",
            "EPOCH 3 completed. learning_rate= 0.000547, Training Loss: 0.0825\n",
            "EPOCH 4 completed. learning_rate= 0.000547, Training Loss: 0.0784\n",
            "EPOCH 5 completed. learning_rate= 0.000547, Training Loss: 0.0811\n",
            "Validation set: Avg. loss: 0.8051, Accuracy: 1866/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000547, Training Loss: 0.0833\n",
            "EPOCH 2 completed. learning_rate= 0.000547, Training Loss: 0.0815\n",
            "EPOCH 3 completed. learning_rate= 0.000547, Training Loss: 0.0793\n",
            "EPOCH 4 completed. learning_rate= 0.000547, Training Loss: 0.0800\n",
            "EPOCH 5 completed. learning_rate= 0.000547, Training Loss: 0.0816\n",
            "Validation set: Avg. loss: 0.8079, Accuracy: 1906/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000547, Training Loss: 0.0883\n",
            "EPOCH 2 completed. learning_rate= 0.000547, Training Loss: 0.0815\n",
            "EPOCH 3 completed. learning_rate= 0.000547, Training Loss: 0.0811\n",
            "EPOCH 4 completed. learning_rate= 0.000547, Training Loss: 0.0803\n",
            "EPOCH 5 completed. learning_rate= 0.000547, Training Loss: 0.0837\n",
            "Validation set: Avg. loss: 0.8063, Accuracy: 1810/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000547, Training Loss: 0.0863\n",
            "EPOCH 2 completed. learning_rate= 0.000547, Training Loss: 0.0799\n",
            "EPOCH 3 completed. learning_rate= 0.000547, Training Loss: 0.0806\n",
            "EPOCH 4 completed. learning_rate= 0.000547, Training Loss: 0.0795\n",
            "EPOCH 5 completed. learning_rate= 0.000547, Training Loss: 0.0811\n",
            "Validation set: Avg. loss: 0.8019, Accuracy: 1900/5000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000547, Training Loss: 0.0821\n",
            "EPOCH 2 completed. learning_rate= 0.000547, Training Loss: 0.0785\n",
            "EPOCH 3 completed. learning_rate= 0.000547, Training Loss: 0.0814\n",
            "EPOCH 4 completed. learning_rate= 0.000547, Training Loss: 0.0793\n",
            "EPOCH 5 completed. learning_rate= 0.000547, Training Loss: 0.0789\n",
            "Validation set: Avg. loss: 0.8013, Accuracy: 1881/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000212, Training Loss: 0.0802\n",
            "EPOCH 2 completed. learning_rate= 0.000212, Training Loss: 0.0831\n",
            "EPOCH 3 completed. learning_rate= 0.000212, Training Loss: 0.0809\n",
            "EPOCH 4 completed. learning_rate= 0.000212, Training Loss: 0.0795\n",
            "EPOCH 5 completed. learning_rate= 0.000212, Training Loss: 0.0819\n",
            "Validation set: Avg. loss: 0.8085, Accuracy: 1835/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000212, Training Loss: 0.0829\n",
            "EPOCH 2 completed. learning_rate= 0.000212, Training Loss: 0.0823\n",
            "EPOCH 3 completed. learning_rate= 0.000212, Training Loss: 0.0816\n",
            "EPOCH 4 completed. learning_rate= 0.000212, Training Loss: 0.0783\n",
            "EPOCH 5 completed. learning_rate= 0.000212, Training Loss: 0.0827\n",
            "Validation set: Avg. loss: 0.8032, Accuracy: 1879/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000212, Training Loss: 0.0934\n",
            "EPOCH 2 completed. learning_rate= 0.000212, Training Loss: 0.0871\n",
            "EPOCH 3 completed. learning_rate= 0.000212, Training Loss: 0.0852\n",
            "EPOCH 4 completed. learning_rate= 0.000212, Training Loss: 0.0858\n",
            "EPOCH 5 completed. learning_rate= 0.000212, Training Loss: 0.0805\n",
            "Validation set: Avg. loss: 0.8371, Accuracy: 1708/5000 (34%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000212, Training Loss: 0.0880\n",
            "EPOCH 2 completed. learning_rate= 0.000212, Training Loss: 0.0836\n",
            "EPOCH 3 completed. learning_rate= 0.000212, Training Loss: 0.0863\n",
            "EPOCH 4 completed. learning_rate= 0.000212, Training Loss: 0.0853\n",
            "EPOCH 5 completed. learning_rate= 0.000212, Training Loss: 0.0810\n",
            "Validation set: Avg. loss: 0.8154, Accuracy: 1802/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000212, Training Loss: 0.0846\n",
            "EPOCH 2 completed. learning_rate= 0.000212, Training Loss: 0.0846\n",
            "EPOCH 3 completed. learning_rate= 0.000212, Training Loss: 0.0756\n",
            "EPOCH 4 completed. learning_rate= 0.000212, Training Loss: 0.0753\n",
            "EPOCH 5 completed. learning_rate= 0.000212, Training Loss: 0.0778\n",
            "Validation set: Avg. loss: 0.8062, Accuracy: 1843/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000258, Training Loss: 0.0898\n",
            "EPOCH 2 completed. learning_rate= 0.000258, Training Loss: 0.0892\n",
            "EPOCH 3 completed. learning_rate= 0.000258, Training Loss: 0.0821\n",
            "EPOCH 4 completed. learning_rate= 0.000258, Training Loss: 0.0838\n",
            "EPOCH 5 completed. learning_rate= 0.000258, Training Loss: 0.0829\n",
            "Validation set: Avg. loss: 0.8060, Accuracy: 1890/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000258, Training Loss: 0.0861\n",
            "EPOCH 2 completed. learning_rate= 0.000258, Training Loss: 0.0798\n",
            "EPOCH 3 completed. learning_rate= 0.000258, Training Loss: 0.0830\n",
            "EPOCH 4 completed. learning_rate= 0.000258, Training Loss: 0.0796\n",
            "EPOCH 5 completed. learning_rate= 0.000258, Training Loss: 0.0783\n",
            "Validation set: Avg. loss: 0.8015, Accuracy: 1892/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000258, Training Loss: 0.0947\n",
            "EPOCH 2 completed. learning_rate= 0.000258, Training Loss: 0.0937\n",
            "EPOCH 3 completed. learning_rate= 0.000258, Training Loss: 0.0849\n",
            "EPOCH 4 completed. learning_rate= 0.000258, Training Loss: 0.0761\n",
            "EPOCH 5 completed. learning_rate= 0.000258, Training Loss: 0.0844\n",
            "Validation set: Avg. loss: 0.8266, Accuracy: 1733/5000 (34%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000258, Training Loss: 0.0922\n",
            "EPOCH 2 completed. learning_rate= 0.000258, Training Loss: 0.0828\n",
            "EPOCH 3 completed. learning_rate= 0.000258, Training Loss: 0.0782\n",
            "EPOCH 4 completed. learning_rate= 0.000258, Training Loss: 0.0820\n",
            "EPOCH 5 completed. learning_rate= 0.000258, Training Loss: 0.0791\n",
            "Validation set: Avg. loss: 0.8138, Accuracy: 1834/5000 (36%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000258, Training Loss: 0.0844\n",
            "EPOCH 2 completed. learning_rate= 0.000258, Training Loss: 0.0824\n",
            "EPOCH 3 completed. learning_rate= 0.000258, Training Loss: 0.0808\n",
            "EPOCH 4 completed. learning_rate= 0.000258, Training Loss: 0.0789\n",
            "EPOCH 5 completed. learning_rate= 0.000258, Training Loss: 0.0791\n",
            "Validation set: Avg. loss: 0.8064, Accuracy: 1818/5000 (36%)\n",
            "\n",
            "Best performance: Validation Accuracy=39%,  Test Accuracy=39%, with SGD optimizer learning_rate=0.0008024939491127563 and momentum=0.9776929046267725\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}